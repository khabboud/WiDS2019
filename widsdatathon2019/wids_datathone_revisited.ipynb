{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "wids_workshop.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McT5BLq7BNIf",
        "colab_type": "text"
      },
      "source": [
        "# WiDS 2019 Datathone revisited: \n",
        "## Binary classification of oil palm satellite images\n",
        "##  Image augmentation for class balancing and transfer learning using Keras API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f2ULO6Waec4",
        "colab_type": "code",
        "outputId": "49c1bec0-4c14-4f4a-b3ba-c39aae8d022c",
        "colab": {}
      },
      "source": [
        "# Includes the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pylab as plt \n",
        "import os\n",
        "\n",
        "from keras import layers\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding, Flatten, Dense, Activation, BatchNormalization, Conv2D, MaxPooling2D, Dropout, Dense, GlobalAveragePooling2D\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import Callback, ModelCheckpoint, History \n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras import applications\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "import multiprocessing\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "\n",
        "import sys, os\n",
        "sys.path.insert(0, '../')\n",
        "from oilpalm import OilPalmImages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lercW8VaedE",
        "colab_type": "code",
        "outputId": "7756a417-8fbc-47ce-da5a-1817a959d9f2",
        "colab": {}
      },
      "source": [
        "# --- Check if Tensorflow is using GPU (install tensorflow-gpu istead of tensorflow)\n",
        "import tensorflow as tf\n",
        "print(tf.test.is_built_with_cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KCOKwG5I6jn",
        "colab_type": "text"
      },
      "source": [
        "#create an instance from OilPalmImages\n",
        "## Get labels according to the selection criterion and the label confidence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "u6xY1-kyaedI",
        "colab_type": "code",
        "outputId": "4be602e6-1f30-4c1e-bf8e-7948aefea46c",
        "colab": {}
      },
      "source": [
        "#---- create instance of OilPalmImages \n",
        "train_file_directory = \"train_images/\"\n",
        "labels_file_name = 'traininglabels.csv'\n",
        "# --- use the label confidence (probability) assigned when labeling to select the labels/images, hard  \n",
        "label_selection_probability = 0.5 # confidence (probability) threshold for accepting the assigned label\n",
        "label_selection_method = 'soft' # or 'hard' threshold \n",
        "apply_pca = False\n",
        "reduced_image_height = 256\n",
        "max_samples_class0 = 1005\n",
        "max_samples_class1 = 1003\n",
        "op_instance = OilPalmImages(file_directory= train_file_directory, labels_file_name = labels_file_name, apply_pca = apply_pca,\n",
        "                            pca_components= reduced_image_height, label_selection_probability = label_selection_probability, \n",
        "                            label_selection_method = label_selection_method,  max_samples_class0 = max_samples_class0,\n",
        "                            max_samples_class1 =max_samples_class1)\n",
        "#---- For Keras, we will only get the labels from file, we will not use the custom readImages member method\n",
        "op_instance.get_labels_from_file()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "plot the distribution of the score value for each of the classes...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/seaborn/axisgrid.py:230: UserWarning: The `size` paramter has been renamed to `height`; please update your code.\n",
            "  warnings.warn(msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 777.6x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "plot the histogram of classes of the training samples...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJAVUQchJeKz",
        "colab_type": "text"
      },
      "source": [
        "## create data frame for the image file names and their labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ITeDoqlnaedN",
        "colab_type": "code",
        "outputId": "45dd766d-7085-4425-ccbe-9b5690796706",
        "colab": {}
      },
      "source": [
        "df_labels = pd.DataFrame()\n",
        "df_labels['img_filename'] = op_instance.labels_dic.keys()\n",
        "df_labels['img_label'] = list(map(lambda x: op_instance.get_label_forImage(x), op_instance.labels_dic.keys()))\n",
        "\n",
        "plt.hist(df_labels.img_label.values)\n",
        "plt.xlabel('has_oilpalm class')\n",
        "plt.show()\n",
        "df_labels['img_label'] = df_labels['img_label'].astype(str)\n",
        "print(\"Available labeled data balance in the raw data\")\n",
        "print(df_labels.img_label.value_counts())\n",
        "\n",
        "df_labels.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0    14241\n",
            "1     1003\n",
            "Name: img_label, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_filename</th>\n",
              "      <th>img_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>img_000002017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>img_000012017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>img_000022017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>img_000072017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>img_000082017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>img_000092017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>img_000102017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>img_000112017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>img_000132017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>img_000142017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        img_filename img_label\n",
              "0  img_000002017.jpg         0\n",
              "1  img_000012017.jpg         0\n",
              "2  img_000022017.jpg         0\n",
              "3  img_000072017.jpg         0\n",
              "4  img_000082017.jpg         0\n",
              "5  img_000092017.jpg         0\n",
              "6  img_000102017.jpg         0\n",
              "7  img_000112017.jpg         0\n",
              "8  img_000132017.jpg         0\n",
              "9  img_000142017.jpg         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl0aMBNWPrn4",
        "colab_type": "text"
      },
      "source": [
        "#Prepare the data for training\n",
        "## Train- Test split 80%- 20%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2zzhqVAaedQ",
        "colab_type": "code",
        "outputId": "0a232f61-0208-40a5-c67d-4405ec496b6b",
        "colab": {}
      },
      "source": [
        "#--- split the labeled data into train and test set\n",
        "train_df, test_df = train_test_split(df_labels,train_size = 0.80, test_size = 0.20 , random_state=1 )\n",
        "train_df= train_df.reset_index(drop=True)\n",
        "test_df= test_df.reset_index(drop=True)\n",
        "print(\"Train data balance before augmentation\")\n",
        "print(train_df.img_label.value_counts())\n",
        "train_df.tail(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    11381\n",
            "1      814\n",
            "Name: img_label, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_filename</th>\n",
              "      <th>img_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12185</th>\n",
              "      <td>img_002262017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12186</th>\n",
              "      <td>img_073462017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12187</th>\n",
              "      <td>img_041492017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12188</th>\n",
              "      <td>img_004092018.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12189</th>\n",
              "      <td>img_050212018.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12190</th>\n",
              "      <td>img_013262017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12191</th>\n",
              "      <td>img_075642017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12192</th>\n",
              "      <td>img_067662018.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12193</th>\n",
              "      <td>img_003712017.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12194</th>\n",
              "      <td>img_085582018.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            img_filename img_label\n",
              "12185  img_002262017.jpg         0\n",
              "12186  img_073462017.jpg         0\n",
              "12187  img_041492017.jpg         0\n",
              "12188  img_004092018.jpg         0\n",
              "12189  img_050212018.jpg         0\n",
              "12190  img_013262017.jpg         0\n",
              "12191  img_075642017.jpg         0\n",
              "12192  img_067662018.jpg         0\n",
              "12193  img_003712017.jpg         0\n",
              "12194  img_085582018.jpg         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrtxoO7_P7ka",
        "colab_type": "text"
      },
      "source": [
        "## Upsampling the minority class using image augmentation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V29YjeyraedT",
        "colab_type": "code",
        "outputId": "d6b8f472-4de0-4577-a530-9a79f64a894b",
        "colab": {}
      },
      "source": [
        "#------ balance the data by upsampling the minority class (the augmentation will happen later in generation)\n",
        "df_train_0 = train_df[train_df.img_label.values =='0']\n",
        "df_train_1 = train_df[train_df.img_label.values =='1']\n",
        "aug_df_train =pd.DataFrame()\n",
        "for i in range(8):\n",
        "    aug_df_train = aug_df_train.append(df_train_1)\n",
        "    \n",
        "\n",
        "aug_df_train = aug_df_train.reset_index(drop = True)\n",
        "\n",
        "train_df = aug_df_train.append(df_train_0)\n",
        "train_df = train_df.reset_index(drop = True)\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
        "print(\"Train data balance after augmentation\")\n",
        "train_df.img_label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    11381\n",
              "1     6512\n",
              "Name: img_label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RNbs0qXaedb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimization parameters\n",
        "lr = 0.1 # learning rate\n",
        "momentum = 0.9 # momentum\n",
        "epochs = 10 # total epochs\n",
        "decay_rate = 0.1 / epochs # rate at which learning rate is decreased\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4pNzyr-aedf",
        "colab_type": "code",
        "outputId": "1508244a-870b-4234-b464-370f1069a7cb",
        "colab": {}
      },
      "source": [
        "#---- Create train generator split the training data into train and validation \n",
        "#sets and randomly augmeneted the training/validation images using Keras's ImageDataGenerator\n",
        "datagen=ImageDataGenerator(rotation_range=40,\n",
        "                            width_shift_range=0.2,\n",
        "                            height_shift_range=0.2,\n",
        "                            #rescale=1./255, # this messes up the order later in prediction\n",
        "                            shear_range=0.2,\n",
        "                            zoom_range=0.2,\n",
        "                            brightness_range=[0.5, 1.5],\n",
        "                            vertical_flip = True,\n",
        "                            horizontal_flip=True,\n",
        "                            channel_shift_range = 0.2,\n",
        "                            fill_mode='nearest',\n",
        "                            validation_split=0.25)\n",
        "train_generator=datagen.flow_from_dataframe(\n",
        "dataframe=train_df,\n",
        "directory=\"./train_images/\",\n",
        "x_col=\"img_filename\",\n",
        "y_col=\"img_label\",\n",
        "subset=\"training\",\n",
        "target_size=(256, 256),\n",
        "color_mode='rgb',\n",
        "batch_size=batch_size,\n",
        "#save_to_dir = \"./augmented_train_images/\", #uncomment this if you want to save the resulting augmented images\n",
        "#save_prefix='', save_format='jpg',\n",
        "seed=42,\n",
        "shuffle=False, # if True, it will mess up the order later in prediction\n",
        "class_mode=\"categorical\",\n",
        "drop_duplicates= False)\n",
        "\n",
        "valid_generator=datagen.flow_from_dataframe(\n",
        "dataframe=train_df,\n",
        "directory=\"./train_images/\",\n",
        "x_col=\"img_filename\",\n",
        "y_col=\"img_label\",\n",
        "subset=\"validation\",\n",
        "target_size=(256, 256),\n",
        "color_mode='rgb',\n",
        "batch_size=batch_size,\n",
        "seed=42,\n",
        "shuffle=False,  # if True, it will mess up the order later in prediction\n",
        "#save_to_dir = \"./augmented_valid_images/\",  #uncomment this if you want to save the resulting augmented images\n",
        "#save_prefix='', save_format='jpg',    \n",
        "class_mode=\"categorical\",\n",
        "drop_duplicates= False)\n",
        "\n",
        "datagen_test=ImageDataGenerator()\n",
        "\n",
        "test_generator=datagen_test.flow_from_dataframe(\n",
        "dataframe=test_df,\n",
        "directory=\"./train_images/\",\n",
        "x_col=\"img_filename\",\n",
        "y_col=\"img_label\",\n",
        "target_size=(256, 256),\n",
        "color_mode='rgb',\n",
        "batch_size=batch_size,\n",
        "seed=42,\n",
        "shuffle=False,  # if True, it will mess up the order later in prediction\n",
        "class_mode=\"categorical\")\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "print(\"number of training samples \", train_generator.n)\n",
        "print(\"number of validation samples \", valid_generator.n)\n",
        "print(\"number of testing samples \", test_generator.n)\n",
        "print(\"number of positive/negative training samples \")\n",
        "y_train = train_generator.classes\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(unique)\n",
        "print(counts)\n",
        "y_valid = valid_generator.classes\n",
        "print(\"number of positive/negative validation samples \")\n",
        "unique, counts = np.unique(y_valid, return_counts=True)\n",
        "print(unique)\n",
        "print(counts)\n",
        "\n",
        "y_test = test_generator.classes\n",
        "print(\"number of positive/negative test samples \")\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(unique)\n",
        "print(counts)\n",
        "print(\"STEP_SIZE_TRAIN \", STEP_SIZE_TRAIN)\n",
        "print(\"STEP_SIZE_VALID\", STEP_SIZE_VALID)\n",
        "print(\"STEP_SIZE_TEST\", STEP_SIZE_TEST)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13420 validated image filenames belonging to 2 classes.\n",
            "Found 4473 validated image filenames belonging to 2 classes.\n",
            "Found 3049 validated image filenames belonging to 2 classes.\n",
            "number of training samples  13420\n",
            "number of validation samples  4473\n",
            "number of testing samples  3049\n",
            "number of positive/negative training samples \n",
            "[0 1]\n",
            "[8487 4933]\n",
            "number of positive/negative validation samples \n",
            "[0 1]\n",
            "[2894 1579]\n",
            "number of positive/negative test samples \n",
            "[0 1]\n",
            "[2860  189]\n",
            "STEP_SIZE_TRAIN  419\n",
            "STEP_SIZE_VALID 139\n",
            "STEP_SIZE_TEST 95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX-kfNaogEv3",
        "colab_type": "text"
      },
      "source": [
        "## Generator for the hold-out test set (unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-38IL4y4aedm",
        "colab_type": "code",
        "outputId": "bb8a2b09-1e22-46a7-b46d-aa12493e5aad",
        "colab": {}
      },
      "source": [
        "file_names = os.listdir(\"./leaderboard_test_data/\")\n",
        "hold_df = pd.DataFrame()\n",
        "hold_df[\"img_filename\"] = file_names\n",
        "hold_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>img_101862018.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>img_067962017.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>img_063002017.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>img_096162017.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>img_047432018.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>img_031932018.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>img_010552017.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>img_046482017.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>img_039142018.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>img_085602018.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        img_filename\n",
              "0  img_101862018.jpg\n",
              "1  img_067962017.jpg\n",
              "2  img_063002017.jpg\n",
              "3  img_096162017.jpg\n",
              "4  img_047432018.jpg\n",
              "5  img_031932018.jpg\n",
              "6  img_010552017.jpg\n",
              "7  img_046482017.jpg\n",
              "8  img_039142018.jpg\n",
              "9  img_085602018.jpg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8LNtPGcaedt",
        "colab_type": "code",
        "outputId": "9dc4bb55-3468-40ff-f561-40497a040ed8",
        "colab": {}
      },
      "source": [
        "#--- generator for the holdout test set (groundtruth not available)\n",
        "datagen_hold=ImageDataGenerator()\n",
        "hold_generator=datagen_hold.flow_from_dataframe(\n",
        "dataframe=hold_df,\n",
        "directory=\"./leaderboard_test_data/\",\n",
        "x_col=\"img_filename\",\n",
        "target_size=(256, 256),\n",
        "color_mode='rgb',\n",
        "batch_size=1,\n",
        "seed=42,\n",
        "shuffle=False,\n",
        "class_mode=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4356 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST2i5jM7aedz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-----get class weight from the training data\n",
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(train_df.img_label),\n",
        "                                                 train_df.img_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m74E33-Qaed5",
        "colab_type": "code",
        "outputId": "2f0a22f9-a360-4f2a-9e1b-46bce47344a8",
        "colab": {}
      },
      "source": [
        "class_weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.78609085, 1.37384828])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "168ALi4ypbMH",
        "colab_type": "text"
      },
      "source": [
        "## CNN Model: use ResNet as a base model and add two output layers to be fitted by the trained data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykQB2dkDaed9",
        "colab_type": "code",
        "outputId": "7fdb848f-c016-459c-c8a0-255b4c188f01",
        "colab": {}
      },
      "source": [
        "#--- base model on ResNet, remove top layer\n",
        "base_model=applications.resnet50.ResNet50(weights='imagenet',include_top=False, input_shape =(256,256,3), classes=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 07:57:30.103055 140193772812096 deprecation_wrapper.py:119] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0718 07:57:30.110625 140193772812096 deprecation_wrapper.py:119] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0718 07:57:30.114632 140193772812096 deprecation_wrapper.py:119] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0718 07:57:30.129504 140193772812096 deprecation_wrapper.py:119] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0718 07:57:30.129944 140193772812096 deprecation_wrapper.py:119] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0718 07:57:30.712120 140193772812096 deprecation_wrapper.py:119] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0718 07:57:30.756643 140193772812096 deprecation_wrapper.py:119] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-LT8RXaaeeD",
        "colab_type": "code",
        "outputId": "cceda925-2322-467e-fc69-b1da9bf94c54",
        "colab": {}
      },
      "source": [
        "# add two layers over the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "# # let's add a fully-connected layer\n",
        "#\n",
        "x = Dense(200, activation='tanh')(x)\n",
        "x = BatchNormalization(axis=-1)(x)\n",
        "x = Dropout(0.4)(x)\n",
        "# and a logistic layer with two output classes\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "model.compile(optimizer=SGD(lr=lr, momentum=momentum, decay=decay_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])    \n",
        "# model.compile(optimizer='rmsprop',loss='binary_crossentropy',\n",
        "#               metrics=['accuracy'])    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 07:57:35.740801 140193772812096 deprecation.py:506] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0718 07:57:35.826035 140193772812096 deprecation_wrapper.py:119] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWzsPD2oaeeS",
        "colab_type": "code",
        "outputId": "a3a5e08e-dc67-4cd2-da1f-34d7685124c6",
        "colab": {}
      },
      "source": [
        "#---number of available CPUs \n",
        "multiprocessing.cpu_count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9jSctYVNaeeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weight2 =class_weight.copy()\n",
        "# class_weight2[1] = class_weight2[1]*2\n",
        "# transform the class weight to dictionary\n",
        "weight_dic = dict()\n",
        "weight_dic[0] = class_weight2[0]\n",
        "weight_dic[1] = class_weight2[1]\n",
        "weight_dic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHiEKLggaeec",
        "colab_type": "code",
        "outputId": "d727fb23-5b9b-4bc2-8e34-dd5ff57ea29e",
        "colab": {}
      },
      "source": [
        "# Fit the model\n",
        "MODEL_FILE = 'filename.model'\n",
        "\n",
        "num_used_cpu = 2\n",
        "num_epochs = epochs\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                                          steps_per_epoch= STEP_SIZE_TRAIN,\n",
        "                                          epochs=num_epochs,\n",
        "                                          verbose=1,\n",
        "                                          validation_data=valid_generator,\n",
        "                                          validation_steps=STEP_SIZE_VALID,\n",
        "                                          class_weight = weight_dic)\n",
        "                                          #workers=num_used_cpu,\n",
        "#                                           max_queue_size=32,use_multiprocessing=True)\n",
        "\n",
        "model.save(MODEL_FILE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 07:57:35.991030 140193772812096 deprecation.py:323] From /home/asamadan/anaconda3/envs/wids_env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "419/419 [==============================] - 202s 481ms/step - loss: 0.3070 - acc: 0.8910 - val_loss: 0.4098 - val_acc: 0.8554\n",
            "Epoch 2/10\n",
            " 18/419 [>.............................] - ETA: 2:06 - loss: 0.2672 - acc: 0.9086"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y5zGvfFQkVv",
        "colab_type": "text"
      },
      "source": [
        "## Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-GkvLFlaeeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the loss function and the evaluation metric over the course of training\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "# Plot accuracy\n",
        "ax.plot(np.array(history.history['acc']), color='blue', label='training accuracy')\n",
        "# Plot loss\n",
        "ax.plot(np.array(history.history['loss']), color='red', label='training loss')\n",
        "ax.set_title('optimizer={}, learning rate={}'.format('Adam', lr))\n",
        "ax.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfX0Ha_Eaeej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate_generator(generator=valid_generator,\n",
        "steps=STEP_SIZE_VALID)\n",
        "print(\"Validation Accuracy = \", scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ZmjNpnaeem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_scores = model.evaluate_generator(generator=train_generator,\n",
        "steps=STEP_SIZE_TRAIN)\n",
        "print(\"Train Accuracy = \", train_scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAcgBKgkaeeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator.reset()\n",
        "test_scores = model.evaluate_generator(generator=test_generator,\n",
        "steps=STEP_SIZE_TEST)\n",
        "print(\"Test Accuracy = \", test_scores[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yHEMZY2aeez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_generator.reset()\n",
        "y_valid = valid_generator.classes\n",
        "y_valid_pred = model.predict_generator(valid_generator,valid_generator.n // batch_size+1,use_multiprocessing=False)\n",
        "y_valid_pred_classes = np.argmax(y_valid_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXU_OAzwaee1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_valid ,y_valid_pred_classes ).ravel()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knTTvL9xaee3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(tn+tp)/(tn+fp+fn+tp )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib2NeNnraee6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unique, counts = np.unique(y_valid, return_counts=True)\n",
        "print(unique)\n",
        "print(counts)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvBLBxnxaee9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_generator.reset()\n",
        "y_test = test_generator.classes\n",
        "y_test_pred = model.predict_generator(test_generator,test_generator.n // batch_size+1,use_multiprocessing=False)\n",
        "y_test_pred_classes = np.argmax(y_test_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urhM4ACuaefB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test,y_test_pred_classes ).ravel()\n",
        "(tn+tp)/(tn+fp+fn+tp )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuQHHFKwaefJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator.reset()\n",
        "y_train = train_generator.classes\n",
        "y_train_pred = model.predict_generator(train_generator,train_generator.n // batch_size+1,use_multiprocessing=False)\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "\n",
        "# print('Train ROC:', roc_auc_score(y_train, y_train_pred))\n",
        "# y_pred[y_pred > 0.5] = 1\n",
        "# y_pred[y_pred <= 0.5] = 0\n",
        "# Compute the confusion matrix on the training set\n",
        "print('Train confusion matrix:\\n', confusion_matrix(y_train,y_train_pred_classes), '\\n\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvzlfz5gaefM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_train,y_train_pred_classes).ravel()\n",
        "                                   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huUcFvtNaefP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(tn+tp)/(tn+fp+fn+tp )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWwi2rKNaefV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the ROC on the training set\n",
        "# print('Valid ROC:', roc_auc_score(y_valid, y_valid_pred))\n",
        "# y_pred[y_pred > 0.5] = 1\n",
        "# y_pred[y_pred <= 0.5] = 0\n",
        "# Compute the confusion matrix on the training set\n",
        "print('Validation confusion matrix:\\n', confusion_matrix(y_valid,y_valid_pred_classes), '\\n\\n')\n",
        "\n",
        "\n",
        "\n",
        "# Get the class probabilities predicted by our MLP on the test set\n",
        "# y_pred = cnn_model.predict(X_test.reshape((-1, op_instance.height, op_instance.width, 1)))\n",
        "# Compute the ROC on the test set\n",
        "# print('Test ROC:', roc_auc_score(y_test, y_test_pred))\n",
        "# Compute the confusion matrix on the test set\n",
        "# y_pred[y_pred > 0.5] = 1\n",
        "# y_pred[y_pred <= 0.5] = 0\n",
        "print('Test confusion matrix:\\n', confusion_matrix(y_test, y_test_pred_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxQk3J_baefY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.matshow(confusion_matrix(y_train, y_train_pred_classes))\n",
        "plt.title('Training confusion matrix')\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "plt.matshow(confusion_matrix(y_valid, y_valid_pred_classes))\n",
        "plt.title('Validation confusion matrix')\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "plt.matshow(confusion_matrix(y_test, y_test_pred_classes))\n",
        "plt.title('Testing confusion matrix')\n",
        "plt.colorbar()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vzt7azuUQU0",
        "colab_type": "text"
      },
      "source": [
        "# Predict the existance of palm oil plantation in holdout test set and save the output to csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKGTOl5Zaefe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hold_generator.reset()\n",
        "y_hold_pred = model.predict_generator(hold_generator,hold_generator.n // 1,use_multiprocessing=False)\n",
        "y_hold_pred_classes = np.argmax(y_hold_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIYEMLMmUPo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_res = pd.DataFrame()\n",
        "test_res['image_id'] = hold_generator.filenames\n",
        "test_res['has_oilpalm'] = y_hold_pred_classes\n",
        "test_res.to_csv('test_results_wids.csv', index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}